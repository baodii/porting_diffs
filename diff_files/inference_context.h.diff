--- generated_code/csrc/transformer/inference/includes/inference_context.h	2023-06-08 22:43:13.717967801 -0700
+++ manual_fixed/csrc/transformer/inference/includes/inference_context.h	2023-06-13 01:45:54.523767061 -0700
@@ -5,15 +5,18 @@
 
 #pragma once
 
+
 #include <sycl/sycl.hpp>
 #include <dpct/dpct.hpp>
-#include <c10/cuda/CUDAStream.h>
+#include <c10/core/Stream.h>
+#include <ipex.h>
+#include <torch/extension.h>
+#include <torch/library.h>
 #include <cassert>
 #include <iostream>
 #include <vector>
-#include <dpct/blas_utils.hpp>
-
-#include <cmath>
+#include <oneapi/mkl.hpp>
+#include <oneapi/mkl/rng/device.hpp>
 
 #define MEGABYTE (1024 * 1024)
 #define GIGABYTE (1024 * 1024 * 1024)
@@ -60,15 +63,18 @@
           _attention_unfused_workspace_offset(0),
           _workSpaceSize(0)
     {
+        dpct::device_ext &dev_ct1 = dpct::get_current_device();
+        _cublasHandle = dev_ct1.default_queue();
+  
         _workSpaceSize = 0;
         _workspace = 0;
-        if (cublasCreate(&_cublasHandle) != CUBLAS_STATUS_SUCCESS) {
+        if (0) {
             auto message = std::string("Fail to create cublas handle.");
             std::cerr << message << std::endl;
             throw std::runtime_error(message);
         }
 #ifndef __HIP_PLATFORM_HCC__
-        cublasSetMathMode(_cublasHandle, CUBLAS_TENSOR_OP_MATH);
+        /* cublasSetMathMode(_cublasHandle, CUBLAS_TENSOR_OP_MATH); */
 #endif
         _comp1_event = new sycl::event();
         _comp2_event = new sycl::event();
@@ -78,7 +84,7 @@
 
     virtual ~InferenceContext()
     {
-        cublasDestroy(_cublasHandle);
+        /* cublasDestroy(_cublasHandle); */
         sycl::free(_workspace, dpct::get_default_queue());
         dpct::destroy_event(_comp1_event);
         dpct::destroy_event(_comp2_event);
@@ -126,19 +132,20 @@
         size_t temp_size = batch_size * (num_heads / mp_size) * max_out_tokens;
         size_t cache_size =
             num_layers * batch_size * ((num_heads * effective_head_size) / mp_size) * 2;
-        size_t minimal_requirements =
-            temp_size + (_free_memory_size > GIGABYTE ? 500 : 100) * MEGABYTE;
-        if (_free_memory_size < minimal_requirements) {
-            printf("Requested:\t%lu\nFree:\t%lu\nTotal:\t%lu\n",
-                   minimal_requirements,
-                   _free_memory_size,
-                   total_size);
-            throw std::runtime_error("Workspace can't be allocated, no enough memory.");
-        }
-
-        _max_seq_len = ((_free_memory_size - minimal_requirements) / elem_size) /
-                       (activation_size + temp_size + cache_size);
-        _max_seq_len = std::min((size_t)max_out_tokens, _max_seq_len);
+        /* size_t minimal_requirements = */
+        /*     temp_size + (_free_memory_size > GIGABYTE ? 500 : 100) * MEGABYTE; */
+        /* if (_free_memory_size < minimal_requirements) { */
+        /*     printf("Requested:\t%lu\nFree:\t%lu\nTotal:\t%lu\n", */
+        /*            minimal_requirements, */
+        /*            _free_memory_size, */
+        /*            total_size); */
+        /*     throw std::runtime_error("Workspace can't be allocated, no enough memory."); */
+        /* } */
+
+        /* _max_seq_len = ((_free_memory_size - minimal_requirements) / elem_size) / */
+        /*                (activation_size + temp_size + cache_size); */
+        /* _max_seq_len = std::min((size_t)max_out_tokens, _max_seq_len); */
+        _max_seq_len = (size_t)max_out_tokens;
         size_t workSpaceSize = ((external_cache ? (activation_size + temp_size)
                                                 : (activation_size + temp_size + cache_size))) *
                                _max_seq_len * elem_size;
@@ -211,22 +218,24 @@
 
     inline void advance_tokens() { _num_tokens++; }
 
-    dpct::queue_ptr GetCommStream(bool async_op = false)
-    {
-        if (!_comm_stream)
-            _comm_stream = async_op ? at::cuda::getStreamFromPool(true)
-                                    : at::cuda::getCurrentCUDAStream();
-        return _comm_stream;
-    }
+    /* dpct::queue_ptr GetCommStream(bool async_op = false) */
+    /* { */
+    /*     if (!_comm_stream) */
+    /*         _comm_stream = async_op ? at::cuda::getStreamFromPool(true) */
+    /*                                 : at::cuda::getCurrentCUDAStream(); */
+    /*     return _comm_stream; */
+    /* } */
     dpct::queue_ptr GetCurrentStream(bool other_stream = false)
     {
-        // get current pytorch stream.
-        if (other_stream) {
-            if (!_stream) _stream = at::cuda::getStreamFromPool(true);
-            return _stream;
-        }
-        dpct::queue_ptr stream = at::cuda::getCurrentCUDAStream();
-        return stream;
+        /* dpct::device_ext &dev_ct1 = dpct::get_current_device(); */
+        /* dpct::queue_ptr stream1; */
+        /* stream1 = dev_ct1.create_queue(); */
+        /* return stream1; */
+        auto type_ = c10::DeviceType::XPU;
+        c10::impl::VirtualGuardImpl impl(type_);
+        auto device_ = c10::Device(type_);
+        c10::Stream stream = impl.getStream(device_);
+        return &xpu::get_queue_from_stream(stream);
     }
 
     void release_workspace()
@@ -240,7 +249,7 @@
         _workspace = (void*)sycl::malloc_device(_workSpaceSize, dpct::get_default_queue());
         return _workspace != nullptr;
     }
-    dpct::queue_ptr GetCublasHandle() { return _cublasHandle; }
+    dpct::queue_ptr GetCublasHandle() { return &_cublasHandle; }
 
     std::pair<uint64_t, uint64_t> IncrementOffset(uint64_t offset_inc)
     {
@@ -253,19 +262,20 @@
 
     const std::vector<std::array<int, 3>>& GetGemmAlgos() const { return _gemm_algos; }
 
-    inline void SynchComp()
-    {
-        cudaEventRecord(_comp_event, _comp_stream);
-        cudaStreamWaitEvent(_comm_stream, _comp_event, 0);
-    }
-    inline void SynchComm()
-    {
-        cudaEventRecord(_comm_event, _comm_stream);
-        cudaStreamWaitEvent(_comp_stream, _comm_event, 0);
-    }
+    /* inline void SynchComp() */
+    /* { */
+    /*     cudaEventRecord(_comp_event, _comp_stream); */
+    /*     cudaStreamWaitEvent(_comm_stream, _comp_event, 0); */
+    /* } */
+    /* inline void SynchComm() */
+    /* { */
+    /*     cudaEventRecord(_comm_event, _comm_stream); */
+    /*     cudaStreamWaitEvent(_comp_stream, _comm_event, 0); */
+    /* } */
 
 private:
-    cublasHandle_t _cublasHandle;
+    /* cublasHandle_t _cublasHandle; */
+    sycl::queue _cublasHandle;
 
     dpct::event_ptr _comp_event;
     dpct::event_ptr _comm_event;
